{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridworld is an example of a finite Markov Decision Process, first introduced in Chapter 3, Example 3.8 and Figure 3.5.\n",
    "\n",
    "The code below calculates the state value function of a random policy based on experience (compare *every-visit Monte Carlo method* from Chapter 5).\n",
    "\n",
    "The gridworld is represented as a 4x4 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def grid_walk(numsteps):\n",
    "    # Four different actions: north, east, south, west\n",
    "    steps = np.array([[0,-1], [-1,0], [0,1], [1,0]], dtype=int)\n",
    "    \n",
    "    # positions[t,:]: Position at time t\n",
    "    positions = np.zeros((numsteps+1,2),dtype=int)\n",
    "    # position_count[x,y]: The number of times we visited position (x,y)\n",
    "    position_count = np.zeros((5,5), dtype=int)\n",
    "    # rewards[t]: Reward at time t\n",
    "    rewards = np.zeros((numsteps+1,), dtype=int)\n",
    "    \n",
    "    # Starting position\n",
    "    initial_position = np.random.randint(5,size=(1,2))\n",
    "    positions[0,:] = initial_position\n",
    "    position_count[initial_position[0,0], initial_position[0,1]] += 1\n",
    "\n",
    "    for i in range(numsteps): \n",
    "        # Draw a random step\n",
    "        step = steps[np.random.randint(4),:]\n",
    "        \n",
    "        # If we are at special positions A or B, move to A' or B'\n",
    "        # and give appropriate reward.\n",
    "        if np.array_equal(positions[i], [0,1]):\n",
    "            positions[i+1] = np.array([4,1])\n",
    "            rewards[i+1] = 10\n",
    "        elif np.array_equal(positions[i], [0,3]):\n",
    "            positions[i+1] = np.array([2,3])\n",
    "            rewards[i+1] = 5\n",
    "        else:\n",
    "            target = positions[i] + step\n",
    "            # If target is outside of the world, produce negative reward and\n",
    "            # stay where you are\n",
    "            if ((target[0] < 0 or target[0] > 4 or target[1] < 0 or target[1] > 4)):\n",
    "                positions[i+1] = positions[i]\n",
    "                rewards[i+1] = -1\n",
    "            else:\n",
    "                positions[i+1,:] = target\n",
    "                rewards[i+1] = 0\n",
    "                \n",
    "        position_count[positions[i+1,0], positions[i+1,1]] += 1\n",
    "    \n",
    "    return rewards, positions, position_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.69647781,  8.48136875,  3.9202212 ,  5.56799172,  0.83541671],\n",
       "        [ 1.52943283,  2.9095513 ,  2.54283748,  2.63804944,  0.64540999],\n",
       "        [-0.08600168,  0.68325262,  0.84694514,  0.79721515, -0.22778448],\n",
       "        [-0.8340392 , -0.39077999, -0.33606378, -0.50772009, -1.19792692],\n",
       "        [-1.72768181, -1.30576507, -1.17340761, -1.40711759, -2.03788446]]),\n",
       " array([[110, 114,  93, 131, 109],\n",
       "        [229, 239, 266, 267, 261],\n",
       "        [382, 423, 422, 530, 426],\n",
       "        [563, 609, 549, 541, 536],\n",
       "        [722, 777, 654, 548, 500]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Play the game\n",
    "numsteps = 10000\n",
    "rewards, positions, position_count = grid_walk(numsteps)\n",
    "\n",
    "# gamma: discount rate\n",
    "gamma = 0.9\n",
    "# state_values[i,j]: value of state (i,j)\n",
    "state_values = np.zeros((5,5))\n",
    "\n",
    "# For each position (i,j) in the gridworld...\n",
    "for i,j in itertools.product(range(5), range(5)):\n",
    "    # See when we visited it\n",
    "    indexes = np.where(np.all(positions[:-1] == [i,j], axis=1))[0]\n",
    "    \n",
    "    # Calculate average discounted return\n",
    "    discounting = np.zeros((numsteps+1,))\n",
    "    for index in indexes:\n",
    "        discounting[(index+1)] += 1\n",
    "        discounting[(index+2):] += np.cumprod(np.repeat(gamma, numsteps + 1 - index - 2))\n",
    "    state_values[i,j] = np.dot(rewards, discounting) / len(indexes)\n",
    "\n",
    "state_values, position_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
